# Аутентификация и пул: PgBouncer, Odyssey и идея «auth отдельно»

## Что такое «соединение» и «пул»

### Соединение в контексте PostgreSQL

**Соединение** — это один TCP-канал до процесса PostgreSQL плюс один «бэкенд» на стороне сервера. Жизненный цикл:

1. Установка TCP.
2. **Startup**: клиент шлёт сообщение Startup (user, database, параметры).
3. **Auth**: сервер может запросить пароль (R), клиент шлёт PasswordMessage (p), сервер отвечает AuthenticationOk (R) и т.д.
4. Сервер шлёт ParameterStatus (S), BackendKeyData (K), ReadyForQuery (Z).
5. Дальше по этому каналу идут только запросы и ответы (Query, Parse, Bind, Execute, ...).

У каждого соединения свой контекст на сервере: один пользователь, одна БД, свои session variables, временные объекты, транзакция. То есть **одно соединение = один «логин» в PostgreSQL**.

### Что такое «соединения из пула» в PgBouncer и Odyssey

Пул — это набор **уже открытых** соединений к PostgreSQL, которые прошли шаги 1–4 выше (ReadyForQuery) и сейчас **ни за кем не закреплены**. Они не «под кем-то»: их открыл **сам пулер** от имени какого-то пользователя/БД (из конфига или из учётных данных клиента после проверки пароля). Как они появляются:

- **По требованию**: первый клиент с (user, db) подключается → пулер открывает новое соединение к PostgreSQL под этим user/db, делает на нём startup (пулер сам шлёт пароль из auth_file или из того, что клиент прислал при auth). После ReadyForQuery это соединение «привязывается» к клиенту. Когда клиент отпускает (disconnect или конец транзакции/запроса) — пулер **не закрывает** соединение, а кладёт его в пул как idle. Следующий клиент с тем же (user, db) может получить это же соединение из пула.
- **Предзаполнение (min_pool_size / warmup)**: в настройках задают, например, «держать минимум 5 соединений к этой БД». При старте или когда пул опустошается пулер сам открывает соединения к PostgreSQL (логин/пароль из конфига), делает полный startup и кладёт их в пул. Эти соединения изначально «ни под кем» — они просто ждут, пока какой-то клиент запросит соединение с тем же (user, db).

Итого: **готовое соединение в пуле** = TCP + завершённый startup на стороне PostgreSQL (ReadyForQuery), принадлежит пулеру, не привязано к клиенту, может быть выдано любому подходящему клиенту (тот же user/database).

### Зачем возвращать auth-соединение в пул (в нашей схеме)

Auth-соединение мы открыли «под» клиентом только ради проверки пароля; оно **не из пула**. Но если мы его просто закроем и при этом **не делаем предзаполнение пула**, то при первом же запросе клиента (Transaction/Statement) пул пуст — брать нечего. Варианты:

1. **Не возвращать в пул** — тогда при первом запросе пул пуст. Либо возвращаем ошибку «sorry, too many clients», либо открываем новое соединение и снова делаем startup — но пароль у нас не храним, повторный auth без клиента невозможен.
2. **Вернуть auth-соединение в пул** — мы не «забираем из пула», мы **добавляем** в пул только что использованное соединение. Тогда при первом запросе клиента в пуле уже есть хотя бы одно соединение (то самое), и мы его выдаём. Так мы и «закрыли» его с точки зрения сессии (клиент в WaitingForBackend), и не теряем ресурс.

Если бы пул был **предзаполнен** при старте (warmup по pool_size/min_pool_size), то auth-соединение можно было бы не класть в пул — просто закрыть. Тогда при первом запросе клиент получил бы одно из заранее открытых соединений. Сейчас у нас предзаполнения нет, поэтому возврат auth-соединения в пул — способ и «закрыть» его для сессии, и дать клиенту что взять при первом запросе.

---

## Как у них сверяется пароль (MD5 / SCRAM-SHA-256)

У PgBouncer и Odyssey проверка пароля делается **по хранимому хешу**, без передачи пароля на бэкенд для проверки.

### MD5

- В БД хранится: `md5` + MD5(password + username) (в `pg_authid.rolpassword` или в userlist).
- Сервер шлёт клиенту соль (4 байта). Клиент присылает: `MD5( stored_inner_hash + salt )`.
- Пулер при **auth_file** или **auth_query** имеет этот же stored hash (например из `SELECT rolpassword FROM pg_authid`). Он сам генерирует соль, шлёт клиенту AuthenticationRequest(MD5, salt), получает ответ и считает `MD5(stored_hash + salt)` — сверяет с тем, что прислал клиент. **Пароль в открытом виде не нужен**, достаточно хеша.

### SCRAM-SHA-256

- В БД хранится строка вида:  
  `SCRAM-SHA-256$<iterations>:<salt>$<storedkey>:<serverkey>`  
  (StoredKey и ServerKey — производные от пароля через PBKDF2).
- Обмен идёт по RFC 5802: клиент шлёт client-first-message, сервер — server-first-message (соль, итерации), клиент — client-final-message с доказательством того, что знает пароль.
- Пулер, имея **тот же SCRAM-секрет** (из userlist или auth_query), может сам проверить client-final-message: по StoredKey проверяется доказательство клиента. То есть проверка снова **по хешу/секрету**, не по открытому паролю.

**Итог:** и MD5, и SCRAM они проверяют **по хешу** (или SCRAM-строке из БД). Пароль в открытом виде нужен только если пулер сам потом открывает соединение к бэку от имени этого пользователя — тогда пароль либо берётся из того, что клиент прислал при auth (и кэшируется на время сессии), либо из конфига (auth_file с plaintext / password).

---

## Как устроено сейчас в PgPooler

- **Новый клиент**: открываем новое соединение с бэком, проксируем его Startup на бэкенд, получаем AuthOK → ParameterStatus → ReadyForQuery, кэшируем ответ, отдаём клиенту. Это соединение используется для запросов до конца транзакции/сессии, потом возвращается в пул.
- **Повторный запрос того же клиента** (после «return to pool»): берём соединение из пула, шлём `DISCARD ALL`, не отдаём клиенту кэшированный startup (сессия уже установлена), переходим в режим форвардинга.

То есть **полный auth (стартап) всегда делается на том же соединении, которое потом идёт в пул и используется для запросов**. Соединение «для auth» не освобождается сразу — оно и есть рабочее соединение сессии/транзакции.

---

## Как сделано в PgBouncer

У PgBouncer аутентификация **не проксируется на бэкенд**. Она делается **на стороне пулера**.

1. **Клиент → PgBouncer**: клиент шлёт Startup (user, database, параметры). PgBouncer **не пересылает** этот Startup на PostgreSQL.
2. **Auth на пулере**:
   - **auth_file (userlist.txt)**: пароли/хеши хранятся в файле; пулер сам шлёт клиенту AuthenticationRequest (MD5/SCRAM/plain), получает ответ, проверяет пароль **локально** (`check_client_passwd`).
   - **auth_user + auth_query**: пулер берёт соединение с бэком от имени **auth_user** (отдельный пул по auth_db + auth_user), выполняет один запрос вида `SELECT usename, passwd FROM pg_authid WHERE ...`, получает хеш пароля пользователя, **сразу отпускает это соединение** (`client->link->resetting = true`, соединение возвращается в пул auth_user). Дальше пулер проверяет пароль клиента **локально** по полученному хешу.
3. **После успешного auth**: пулер сам формирует и шлёт клиенту ответ «успешный логин» (AuthenticationOK, затем ParameterStatus / ReadyForQuery — из кэша или с того бэкенда, который будет выдан клиенту).
4. **Соединение с бэком для запросов**: когда клиент шлёт запросы, пулер берёт/создаёт соединение к PostgreSQL от имени **уже проверенного** пользователя (логин на бэкенд делает сам PgBouncer, используя сохранённые учётные данные). То есть бэкенд **никогда не видит** Startup от клиента — он видит только соединения, открытые пулером от имени этого пользователя.

Итого: **«подмена auth»** в PgBouncer — это как раз то, что ты имел в виду: auth делается на пулере (или через короткое использование отдельного соединения auth_user только для auth_query), а для запросов используется пул соединений, открытых пулером; клиентский Startup на бэкенд не уходит.

---

## Odyssey (кратко)

- Поддерживает auth на уровне пулера (md5, scram-sha-256, clear_text, cert и т.д.) и отдельно — `auth_query` для запроса паролей из БД.
- Как и в PgBouncer, различаются учётные данные для аутентификации клиента и для соединений к storage (бэкенду). То есть концепция та же: **auth решается на стороне пулера**, к бэку идут уже «свои» соединения пулера.

---

## Идея: «только auth на бэке, потом пул»

Ты предлагаешь: **сразу создавать соединение с бэком, гнать на него полный startup (auth), а после того как сессия установилась — отдать клиента на соединение из пула**, чтобы «auth-соединение» долго не держать.

Вариант реализации:

1. **Новый клиент** подключается, шлёт Startup.
2. Открываем **отдельное** (временное) соединение к бэку — **только для auth**: отправляем туда Startup клиента, проходим AuthOK → ParameterStatus → ReadyForQuery.
3. Убедившись, что auth успешен, **закрываем это соединение** (или возвращаем в небольшой «auth-пул») — долго не держим.
4. Берём соединение из **рабочего пула** (тот же backend, user, database).
5. Клиенту **не** шлём повторно полный startup с бэка; отдаём ему **кэшированный** ответ (ParameterStatus, ReadyForQuery) от соединения из пула — как будто сессия уже установлена.
6. Дальше все запросы клиента идут на это соединение из пула.

Так мы действительно «подменяем» сессию: auth проверен на одном соединении, а запросы обслуживаются другим (из пула), без повторной отправки клиентского Startup на бэкенд.

**Сравнение с PgBouncer:**

- **PgBouncer**: вообще не использует бэкенд для проверки пароля клиента (кроме auth_query, где бэкенд даёт только хеш, а проверка — локально). Экономит соединения и не держит «auth-соединение» с бэком под клиента.
- **Наш вариант**: один раз используем бэкенд для полного startup (auth на самом PostgreSQL), затем переключаем клиента на пул. Плюс — не нужны auth_file/auth_query и полная поддержка любого метода auth PostgreSQL (GSSAPI, LDAP и т.д. на бэке). Минус — на каждого нового клиента всё равно одно короткое соединение к бэку только для auth (или пул таких «auth-соединений»).

**Практически** для реализации нужно:

- Либо пул «auth-only» соединений (берём, делаем startup с клиентским Startup, получили ReadyForQuery — отдаём клиенту кэш от пулового соединения, auth-соединение сбрасываем и возвращаем в auth-пул).
- Либо каждый раз новое временное соединение для auth, затем закрыть и взять из основного пула.

Если хочешь, можно в следующем шаге расписать конкретные изменения в `ClientSession` и протокол (состояния, когда мы в «auth-only», когда переключаем на пул и отдаём кэш).

---

## Что лучше: как у них или «auth на бэке, потом пул»

| Критерий | PgBouncer/Odyssey (auth на пулере по хешу) | Твой вариант (auth на бэке, потом handoff в пул) |
|----------|-------------------------------------------|--------------------------------------------------|
| **Сверка пароля** | По хешу: пулер хранит/забирает MD5 или SCRAM-строку, сам проверяет ответ клиента. Пароль на бэк не отправляется для проверки. | Бэкенд сам проверяет: полный startup уходит на PostgreSQL, любые методы (MD5, SCRAM, GSSAPI, LDAP и т.д.) работают без кода в пулере. |
| **Реализация в пулере** | Нужно реализовать протокол auth: MD5, SCRAM-SHA-256, плюс auth_file/auth_query, синхронизация с pg_authid. | Не нужна своя криптография и хранилище паролей — только прокси + handoff. |
| **Нагрузка на бэк** | При auth_query — одно короткое соединение под auth_user на запрос хеша; при auth_file — ноль соединений на auth. Для запросов — пул соединений, открытых пулером. | Одно короткое соединение на каждого нового клиента только для auth (или маленький auth-пул), затем запросы — из общего пула. |
| **Безопасность** | Хеши/SCRAM в пулере или запрос к pg_authid; пароль в открытом виде только если кэшировать для открытия соединений к бэку. | Пароль один раз уходит на бэк по протоколу; пулер не хранит пароли и не реализует проверку. |
| **Гибкость** | Только те методы auth, которые пулер умеет (md5, scram, cert, pam, ldap и т.д.). Новые методы — доработка пулера. | Любой метод, который умеет PostgreSQL; пулер не зависит от типа auth. |

**Кратко:**

- **Как у них**: сверка **по хешу** (MD5 или SCRAM-строка); пулер сам ведёт auth, бэкенд для проверки пароля не используется. Экономия соединений на auth, но нужна своя реализация протоколов и (при auth_query) синхронизация с БД.
- **Твой вариант**: сверку делает **бэкенд**; пулер только проксирует startup на «auth-соединение», потом переключает клиента на пул. Реализация проще (без своей криптографии), поддержка любых методов auth «из коробки», но на каждого нового клиента — одно короткое соединение к бэку под auth.

Для дипломного проекта вариант «auth на бэке, потом пул» часто выгоднее: меньше кода, меньше рисков с паролями/хешами, полная совместимость с любым auth PostgreSQL.

---

## Лимиты пула и все случаи: как у PgBouncer, Odyssey и у нас

### PgBouncer: отдельного «auth-соединения» нет

- **Auth** делается на пулере. К бэкенду пулер обращается только когда нужен **сервер для запросов** (или для auth_query под auth_user — это отдельный маленький пул).
- **pool_size** (default_pool_size) — максимум **серверных** соединений на одну пару (database, user). Это и есть «пул»: idle + in use вместе не больше pool_size.
- **Когда берётся/создаётся сервер:**
  - **Session**: сервер привязывается к клиенту **при логине** (после успешной проверки пароля). Берётся idle из пула или создаётся новое соединение к PostgreSQL (если ещё не достигнут pool_size).
  - **Transaction / Statement**: сервер привязывается **при первом запросе** (начало транзакции или запрос). Снова: взять idle или создать новое (в пределах pool_size).
- **Пул уже полон (все pool_size соединений заняты):**
  - Новый клиент (session) или новый запрос (transaction) не получает сервер сразу. Клиент **ждёт** свободное соединение до **query_wait_timeout**. Если за это время никто не освободил — отключение с ошибкой (pooler error).
  - **Никогда не создаётся «лишнее» соединение**: 21-го при pool_size=20 не бывает. Либо взяли из idle, либо создали новое (если total < pool_size), либо ждём/ошибка.
- **Откуда берутся соединения в пуле изначально:** по мере работы. Первый клиент с (user, db) → пулер создаёт первое соединение к бэку. После release (disconnect или конец транзакции) соединение идёт в idle. Опционально **min_pool_size** — пулер может заранее держать несколько соединений (warmup).

Итого: в PgBouncer нет сценария «прошёл auth отдельным соединением, а потом кладём его в пул». Соединение к бэку появляется только когда «нужен сервер клиенту», и оно сразу считается частью пула (in use, потом idle). Лимит — строго pool_size на (db, user).

---

### Odyssey: та же идея

- Пул ограничен **pool_size** (и опционально **min_pool_size**). Соединения к storage создаются при необходимости (взять из idle или открыть новое в лимите).
- Auth на стороне пулера; к бэкенду идут только «рабочие» соединения для запросов. Отдельного «auth-соединения к бэку» нет.
- При исчерпании пула — ожидание или отказ в зависимости от настроек (аналог query_wait_timeout и лимитов).

---

### Наша модель: auth-соединение и куда его деть

У нас есть **отдельное** соединение для auth. Важно: оно **уже учитывается в лимите**.

- Перед открытием auth-соединения мы вызываем **pool_manager_->acquire(backend_name)**. Лимит — **pool_size на бэкенд** (например 20). Если слотов нет (уже 20 соединений к этому бэку) — **acquire() = false**, мы **не открываем** auth-соединение и сразу отдаём клиенту ошибку «sorry, too many clients already». То есть при «в пуле уже 20» новый клиент не дойдёт до этапа «прошёл auth» — мы его отсекаем до создания 21-го соединения.
- Если **acquire() прошёл** — у нас есть ровно один слот. Мы открываем **одно** соединение к бэку, проксируем по нему auth. После ReadyForQuery:
  - **Session**: пытаемся взять из пула; если пусто — ошибка (как договорились). Если взяли — auth-соединение закрываем (release слот).
  - **Transaction / Statement**: auth-соединение **кладём в пул** (return_backend_to_pool). Мы **не создаём** 21-е соединение: мы **переводим** наше единственное (уже учтённое слотом) в состояние «idle в пуле». Всего соединений к бэку по-прежнему не больше pool_size.
- **«В пуле уже 20, новое прошло auth — положить нельзя?»** — такой ситуации у нас не возникает: мы не открываем auth-соединение, если слотов уже нет. Если же мы auth открыли (значит был свободный слот), то после auth мы либо отдаём это соединение в пул (Tx/Stmt), либо закрываем и выдаём ошибку (Session, если из пула взять не удалось). В любом случае общее число соединений к бэку не превышает pool_size.

Итого: auth-соединение **можно и нужно** класть в пул в режиме Transaction/Statement — мы не «добавляем лишнее», мы возвращаем в пул то единственное соединение, которое только что использовали для auth и которое уже учтено лимитом.

---

## Как чистится пул и случай «пул полный, а у нас новое соединение»

### Случай «пул полный, новое соединение»

- **Лимит** у нас один: `pool_size` на бэкенд = максимум одновременных соединений к этому бэку (и в пуле, и «в работе»).
- **Новое соединение** (auth) мы создаём только после успешного **acquire(backend)**. Если слотов нет (уже 20) — **acquire() = false**, новое соединение **не открываем**, клиенту сразу «sorry, too many clients». То есть ситуация «пул полный и при этом мы уже открыли 21-е соединение» у нас не возникает: 21-го соединения не создаём.
- Если бы мы захотели **всегда** класть auth-соединение в пул, но при этом пул уже полный (например, 20 idle по этому backend/user/db), варианты такие:
  - **Не класть, а закрыть** — auth-соединение закрываем и делаем release. Тогда при первом запросе клиент возьмёт одно из 20 из пула. Мы не превышаем лимит, но один раз «потратили» соединение на auth и сразу его убили.
  - **Ограничить размер пула** — считать не только «в работе», но и «в пуле», и не допускать больше pool_size всего. Тогда при «пул уже полный» при return_backend_to_pool не делать put, а закрыть соединение и release (чистка «лишнего»).

Сейчас мы не ограничиваем размер пула по ключу (backend, user, db): в пуле может лежать сколько угодно idle при общем лимите по бэкенду через acquire/release. Чтобы строго учесть «пул полный» и решить, класть или чистить, нужно явно учитывать «соединения в пуле» в лимите (см. ниже).

### Как пул чистится у конкурентов (по какому принципу удаляется)

**Только про PgBouncer и Odyssey.**

---

#### PgBouncer

Закрытие серверных соединений из пула задаётся **двумя таймаутами** (применяются к соединениям, которые **не привязаны к клиенту**, т.е. лежат в пуле idle):

1. **server_idle_timeout** (по умолчанию 600 сек = 10 мин)  
   Закрыть серверное соединение, если оно **простаивает в пуле** дольше этого времени. То есть критерий — **время простоя (idle)**.

2. **server_lifetime** (по умолчанию 3600 сек = 1 час)  
   Закрыть серверное соединение, если с момента **его создания** прошло больше этого времени, независимо от того, как часто им пользовались. Критерий — **возраст соединения**.

- Оба параметра действуют только на **idle**-соединения (не привязанные к клиенту). Активное соединение не режут по таймаутам.
- Если заданы оба, фактически срабатывает тот таймаут, который наступит раньше.
- В режиме **session** авто-закрытие по этим таймаутам не применяется к соединениям, привязанным к клиенту; в **transaction** и **statement** после возврата в пул соединение снова считается idle и может быть закрыто по server_idle_timeout или server_lifetime.
- **server_lifetime = 0** означает: соединение используется один раз, после возврата в пул его закрывают (агрессивная ротация).
- В документации явно сказано: пулер закрывает соединение «whenever possible» с учётом pool_mode (т.е. не во время транзакции/сессии клиента).

Итого у PgBouncer: удаление из пула — **по времени**: либо «сколько уже лежит в idle», либо «сколько живёт с момента создания».

---

#### Odyssey

Аналогично — **время**, но свои параметры на уровне маршрута (rule):

1. **pool_ttl** (сек, по умолчанию 0 = выключено)  
   **Time-to-live для idle-соединений в пуле.** Если соединение в пуле простаивает дольше `pool_ttl` секунд — его закрывают. Критерий — **время простоя в пуле**.

2. **server_lifetime** (сек, по умолчанию 3600)  
   Максимальное время жизни серверного соединения. Соединение закрывают после этого времени; деаллокация только когда соединение в **idle**. Критерий — **возраст соединения**.

- Оба применяются к соединениям, которые уже в пуле (idle), не к активным клиентским сессиям.

Итого у Odyssey: удаление из пула тоже **по времени** — либо по idle (pool_ttl), либо по возрасту (server_lifetime).

---

**Общий принцип у конкурентов:** пул чистится **по таймаутам**, а не по «очереди» или случайному выбору: закрывают соединения, которые либо слишком долго простаивают в пуле (idle), либо слишком долго живут с момента создания (lifetime). Никакой отдельной логики «какое именно соединение выкинуть» (LIFO/FIFO по ключу и т.п.) в документации не описано — важен только факт «idle дольше N» или «возраст больше M».

---

## Пул полный, нужно новое соединение, таймауты ещё не сработали — как поступают конкуренты

Ситуация: лимит пула (pool_size) достигнут, все соединения заняты или лежат в idle, но ни одно ещё не закрыто по server_idle_timeout / server_lifetime (pool_ttl). Приходит новый клиент (или новый запрос в transaction mode). Новое соединение создавать нельзя — превысим лимит. Почистить пул принудительно нельзя — таймауты не сработали.

**PgBouncer и Odyssey ведут себя одинаково:**

- **Нового соединения не создают** и **ни одно существующее не закрывают** «для места».
- Клиент (или запрос) **ставится в очередь ожидания**: ждёт, пока одно из соединений освободится (клиент отключился, транзакция/запрос завершился — соединение вернулось в пул).
- Ждать можно только ограниченное время:
  - **PgBouncer:** **query_wait_timeout** (сек). Если за это время слот не освободился — клиент отключается с ошибкой (pooler error: query_wait_timeout). При 0 — ждать бесконечно.
  - **Odyssey:** **pool_timeout** (мс). Если за это время соединение из пула не получено — запрос/клиент получает ошибку. При 0 — без лимита ожидания.

Итого: при полном пуле конкуренты **не создают 21-е соединение и не выкидывают существующее по своей инициативе**. Они **ставят в очередь** и дают освободиться одному из текущих (по таймаутам или по возврату в пул). Если за query_wait_timeout / pool_timeout место не освободилось — отказ клиенту.

---

## Откуда знаем, из какого пула давать соединение

В сессии хранятся параметры, заданные при первом подключении (из Startup и роутинга):

- **backend_name_** — имя бэкенда (из `routing.yaml`, например `p1`, `replica`);
- **user_** — пользователь из параметра `user` в Startup;
- **database_** — база из параметра `database` в Startup.

Они выставляются в `connect_to_backend()` при первом вызове (из `resolver_(user, database)` и `pending_startup_`). Пул ключуется по `(backend_name, user, database)`.

Когда клиент в состоянии **WaitingForBackend** (auth уже прошёл, соединение для transaction/statement закрыто) и присылает первый запрос, мы снова вызываем `connect_to_backend()`. К этому моменту **backend_name_, user_, database_** уже установлены, поэтому делаем `connection_pool_->take(backend_name_, user_, database_)` и выдаём клиенту соединение из нужного пула.