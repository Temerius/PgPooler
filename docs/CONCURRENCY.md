# Модель параллельной обработки клиентов

## Как обрабатываются 10+ клиентов

**Отдельные потоки не используются.** Все клиенты обслуживаются в **одном потоке** с одним циклом событий libevent (`event_base_dispatch`).

### Почему другие клиенты не ждут, если один получает гигабайты?

1. **Один бэкенд-коннект на клиента**  
   У каждого клиента своя сессия (`ClientSession`) и **своё** соединение с PostgreSQL. Если клиент A получает 10 ГБ ответа, то читаются/пишутся только сокеты сессии A. Сессии B, C, D… при этом не затронуты.

2. **Неблокирующий I/O**  
   Все сокеты в неблокирующем режиме. Чтение и запись делаются «сколько пришло/сколько вошло» и сразу возвращают управление. Цикл событий не блокируется на одном соединении.

3. **Мультиплексирование в одном потоке**  
   libevent (epoll/kqueue и т.п.) в одном потоке обрабатывает все готовые к I/O дескрипторы. Сработало чтение от клиента 1 — обработали кусок и вышли из callback. Сработало чтение от бэкенда для клиента 2 — обработали. И так по кругу. Никто не «занимает» поток надолго: каждый callback делает небольшую порцию работы и возвращается.

Итог: **10, 100, 1000 клиентов** — все обрабатываются в одном потоке; «тяжёлый» ответ одного клиента не блокирует остальных, потому что у каждого своё соединение с бэкендом и все операции неблокирующие.

### Когда бы другие клиенты ждали?

Только если бы мы делали **один общий** бэкенд-коннект на всех клиентов и гоняли через него запросы по очереди. Сейчас архитектура **1 клиент : 1 бэкенд-коннект** (прозрачный прокси без пулинга), поэтому такой очереди нет.

### Будущий пулинг

Когда появится пул соединений (несколько клиентов делят один бэкенд-коннект), ограничением будет уже не «один поток», а то, что один занятый коннект может обрабатывать только один запрос. Тогда логика «кто на каком коннекте» будет решаться в слое пула, по-прежнему в том же одном потоке и том же event loop.
