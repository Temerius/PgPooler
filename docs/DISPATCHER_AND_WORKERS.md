# Диспетчер и воркеры: один вход, маршрутизация по первому пакету

## Идея

Один процесс слушает порт (диспетчер). Новое клиентское соединение принимается диспетчером. По **первому пакету** (Startup или SSL request → затем Startup) извлекаются `user` и `database`, по ним определяется **бэкенд** (как сейчас в routing). По бэкенду выбирается **воркер** (один воркер = один или несколько бэкендов). Диспетчер **передаёт** клиентский сокет (и уже прочитанные байты) выбранному воркеру. Дальше воркер ведёт сессию как сейчас: свой пул к своему PostgreSQL, свой event loop, без гонок с другими воркерами.

## Зачем

- **Масштабирование по ядрам**: каждый воркер — отдельный процесс (или поток) со своим event loop → загрузка нескольких ядер.
- **Свой пул на воркер**: пул соединений к PostgreSQL принадлежит одному воркеру, общая память только внутри воркера → нет блокировок и гонок между воркерами.
- **Один вход для клиентов**: клиент подключается к одному адресу/порту; маршрутизация внутрь скрыта.

## Компоненты

### 1. Диспетчер (front)

- Слушает один порт (как сейчас listener).
- **Accept** → получили клиентский fd.
- **Читаем первый пакет** в неблокирующем режиме:
  - либо 8 байт SSL request (код 80877103);
  - либо полноценный Startup (длина + сообщение), из него — `user`, `database`.
- По (user, database) вызываем **resolver** → `backend_name`.
- По `backend_name` выбираем **воркер** (из конфига: backend → worker_id, или round-robin по бэкендам).
- **Передача соединения воркеру**:
  - передаём fd воркеру через **Unix domain socket** (SCM_RIGHTS — передача дескриптора другому процессу);
  - вместе с fd отправляем маленький заголовок: длина уже прочитанных данных + сами данные (первый пакет), плюс опционально `backend_name` (или воркер сам резолвит по переданным user/database).
- Воркер получает fd и буфер, создаёт у себя сессию с этим fd и уже накопленным вводом, дальше работает как текущая `ClientSession`.

### 2. Воркеры

- Каждый воркер — отдельный **процесс** (или поток с отдельным event_base).
- У каждого свой `event_base`, свой `PoolManager`, свой `BackendConnectionPool`, свой `ConnectionWaitQueue`.
- Конфиг задаёт, какой воркер за какой бэкенд отвечает, например:
  - worker0 → backends [primary]
  - worker1 → backends [replica]
  или один воркер на один PostgreSQL.
- Воркер слушает **Unix domain socket** (или pipe): принимает от диспетчера fd + буфер.
- Получил fd → создал `ClientSession` с этим fd и переданным буфером в `client_input_`, запустил обработку в своём event loop.

### 3. Маршрутизация backend → worker

- В конфиге (или при старте): список бэкендов и для каждого — `worker_id` (или список воркеров и маппинг backend_name → worker_id).
- Диспетчер держит открытыми сокеты к каждому воркеру; после выбора backend_name шлёт fd в соответствующий сокет.

## Передача fd между процессами (SCM_RIGHTS)

- Диспетчер и воркеры — разные процессы.
- Между ними — Unix domain stream socket (пара сокетов к каждому воркеру или один сокет на воркера).
- Передача fd: `sendmsg()` с `cmsg` типа `SCM_RIGHTS` и дескриптором клиентского fd.
- Воркер: `recvmsg()`, извлекает fd из `cmsg`, добавляет fd в свой event_base (например, создаёт bufferevent или event на этот fd).
- После передачи fd диспетчер его у себя закрывает (больше не использует).

## Что передаём вместе с fd

Минимум:

1. Длина буфера (например, 4 байта).
2. Буфер (уже прочитанный первый пакет от клиента — SSL request или Startup).
3. Опционально: backend_name или (user, database), чтобы воркер не парсил заново и сразу знал, к какому бэкенду цепляться.

Протокол на Unix-сокете может быть свой простой: [len][payload]. В payload — первый пакет клиента и метаданные.

## Конфиг (эскиз)

```yaml
# Сколько воркеров и кто за что отвечает
workers:
  - id: 0
    backends: [primary]   # этот воркер держит пул только к primary
  - id: 1
    backends: [replica]   # этот — только к replica
listen: "0.0.0.0:5432"
worker_sockets: "/run/pgpooler/worker-%d"  # или один сокет и диспетчер сам решает, куда слать
```

Диспетчер при старте создаёт/подключается к сокетам воркеров, воркеры слушают свои сокеты и ждут fd.

## Этапы реализации

1. **Текущий режим сохранить** — один процесс без диспетчера (как сейчас), для обратной совместимости и простого деплоя.
2. **Режим с диспетчером** (опция в конфиге или флаг):
   - процесс-диспетчер: только accept + чтение первого пакета + resolve + отправка fd воркеру;
   - N процессов-воркеров: каждый принимает fd по Unix socket, создаёт сессию, крутит свой event loop с пулами.
3. Конфиг backends/routing без изменений; добавляется только секция workers и способ запуска (один процесс или диспетчер + воркеры).

## Итог

- Один вход (один порт) → диспетчер по первому пакету (user/database) определяет бэкенд → выбирает воркер для этого бэкенда → передаёт соединение (fd + буфер) воркеру через Unix socket.
- У каждого воркера свой пул к своему PostgreSQL, свой поток/ядро, без гонок — как ты и предлагал.
